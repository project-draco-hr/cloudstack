{
  CallContext cctxt=CallContext.current();
  Account account=cctxt.getCallingAccount();
  User caller=cctxt.getCallingUser();
  VMInstanceVO vm=_vmDao.findByUuid(vmUuid);
  VirtualMachineGuru vmGuru=getVmGuru(vm);
  Ternary<VMInstanceVO,ReservationContext,ItWorkVO> start=changeToStartState(vmGuru,vm,caller,account);
  if (start == null) {
    return;
  }
  vm=start.first();
  ReservationContext ctx=start.second();
  ItWorkVO work=start.third();
  VMInstanceVO startedVm=null;
  ServiceOfferingVO offering=_offeringDao.findById(vm.getId(),vm.getServiceOfferingId());
  VirtualMachineTemplate template=_entityMgr.findById(VirtualMachineTemplate.class,vm.getTemplateId());
  if (s_logger.isDebugEnabled()) {
    s_logger.debug("Trying to deploy VM, vm has dcId: " + vm.getDataCenterId() + " and podId: "+ vm.getPodIdToDeployIn());
  }
  DataCenterDeployment plan=new DataCenterDeployment(vm.getDataCenterId(),vm.getPodIdToDeployIn(),null,null,null,null,ctx);
  if (planToDeploy != null && planToDeploy.getDataCenterId() != 0) {
    if (s_logger.isDebugEnabled()) {
      s_logger.debug("advanceStart: DeploymentPlan is provided, using dcId:" + planToDeploy.getDataCenterId() + ", podId: "+ planToDeploy.getPodId()+ ", clusterId: "+ planToDeploy.getClusterId()+ ", hostId: "+ planToDeploy.getHostId()+ ", poolId: "+ planToDeploy.getPoolId());
    }
    plan=new DataCenterDeployment(planToDeploy.getDataCenterId(),planToDeploy.getPodId(),planToDeploy.getClusterId(),planToDeploy.getHostId(),planToDeploy.getPoolId(),planToDeploy.getPhysicalNetworkId(),ctx);
  }
  HypervisorGuru hvGuru=_hvGuruMgr.getGuru(vm.getHypervisorType());
  boolean canRetry=true;
  ExcludeList avoids=null;
  try {
    Journal journal=start.second().getJournal();
    if (planToDeploy != null) {
      avoids=planToDeploy.getAvoids();
    }
    if (avoids == null) {
      avoids=new ExcludeList();
    }
    if (s_logger.isDebugEnabled()) {
      s_logger.debug("Deploy avoids pods: " + avoids.getPodsToAvoid() + ", clusters: "+ avoids.getClustersToAvoid()+ ", hosts: "+ avoids.getHostsToAvoid());
    }
    boolean planChangedByVolume=false;
    boolean reuseVolume=true;
    DataCenterDeployment originalPlan=plan;
    int retry=StartRetry.value();
    while (retry-- != 0) {
      if (reuseVolume) {
        List<VolumeVO> vols=_volsDao.findReadyRootVolumesByInstance(vm.getId());
        for (        VolumeVO vol : vols) {
          Long volTemplateId=vol.getTemplateId();
          if (volTemplateId != null && volTemplateId.longValue() != template.getId()) {
            if (s_logger.isDebugEnabled()) {
              s_logger.debug(vol + " of " + vm+ " is READY, but template ids don't match, let the planner reassign a new pool");
            }
            continue;
          }
          StoragePool pool=(StoragePool)dataStoreMgr.getPrimaryDataStore(vol.getPoolId());
          if (!pool.isInMaintenance()) {
            if (s_logger.isDebugEnabled()) {
              s_logger.debug("Root volume is ready, need to place VM in volume's cluster");
            }
            long rootVolDcId=pool.getDataCenterId();
            Long rootVolPodId=pool.getPodId();
            Long rootVolClusterId=pool.getClusterId();
            if (planToDeploy != null && planToDeploy.getDataCenterId() != 0) {
              Long clusterIdSpecified=planToDeploy.getClusterId();
              if (clusterIdSpecified != null && rootVolClusterId != null) {
                if (rootVolClusterId.longValue() != clusterIdSpecified.longValue()) {
                  if (s_logger.isDebugEnabled()) {
                    s_logger.debug("Cannot satisfy the deployment plan passed in since the ready Root volume is in different cluster. volume's cluster: " + rootVolClusterId + ", cluster specified: "+ clusterIdSpecified);
                  }
                  throw new ResourceUnavailableException("Root volume is ready in different cluster, Deployment plan provided cannot be satisfied, unable to create a deployment for " + vm,Cluster.class,clusterIdSpecified);
                }
              }
              plan=new DataCenterDeployment(planToDeploy.getDataCenterId(),planToDeploy.getPodId(),planToDeploy.getClusterId(),planToDeploy.getHostId(),vol.getPoolId(),null,ctx);
            }
 else {
              plan=new DataCenterDeployment(rootVolDcId,rootVolPodId,rootVolClusterId,null,vol.getPoolId(),null,ctx);
              if (s_logger.isDebugEnabled()) {
                s_logger.debug(vol + " is READY, changing deployment plan to use this pool's dcId: " + rootVolDcId+ " , podId: "+ rootVolPodId+ " , and clusterId: "+ rootVolClusterId);
              }
              planChangedByVolume=true;
            }
          }
        }
      }
      VirtualMachineProfileImpl vmProfile=new VirtualMachineProfileImpl(vm,template,offering,account,params);
      DeployDestination dest=null;
      try {
        dest=_dpMgr.planDeployment(vmProfile,plan,avoids);
      }
 catch (      AffinityConflictException e2) {
        s_logger.warn("Unable to create deployment, affinity rules associted to the VM conflict",e2);
        throw new CloudRuntimeException("Unable to create deployment, affinity rules associted to the VM conflict");
      }
      if (dest == null) {
        if (planChangedByVolume) {
          plan=originalPlan;
          planChangedByVolume=false;
          reuseVolume=false;
          continue;
        }
        throw new InsufficientServerCapacityException("Unable to create a deployment for " + vmProfile,DataCenter.class,plan.getDataCenterId(),areAffinityGroupsAssociated(vmProfile));
      }
      if (dest != null) {
        avoids.addHost(dest.getHost().getId());
        journal.record("Deployment found ",vmProfile,dest);
      }
      long destHostId=dest.getHost().getId();
      vm.setPodId(dest.getPod().getId());
      Long cluster_id=dest.getCluster().getId();
      ClusterDetailsVO cluster_detail_cpu=_clusterDetailsDao.findDetail(cluster_id,"cpuOvercommitRatio");
      ClusterDetailsVO cluster_detail_ram=_clusterDetailsDao.findDetail(cluster_id,"memoryOvercommitRatio");
      if (_uservmDetailsDao.findDetail(vm.getId(),"cpuOvercommitRatio") == null && ((Float.parseFloat(cluster_detail_cpu.getValue()) > 1f || Float.parseFloat(cluster_detail_ram.getValue()) > 1f))) {
        _uservmDetailsDao.addDetail(vm.getId(),"cpuOvercommitRatio",cluster_detail_cpu.getValue());
        _uservmDetailsDao.addDetail(vm.getId(),"memoryOvercommitRatio",cluster_detail_ram.getValue());
      }
 else       if (_uservmDetailsDao.findDetail(vm.getId(),"cpuOvercommitRatio") != null) {
        _uservmDetailsDao.addDetail(vm.getId(),"cpuOvercommitRatio",cluster_detail_cpu.getValue());
        _uservmDetailsDao.addDetail(vm.getId(),"memoryOvercommitRatio",cluster_detail_ram.getValue());
      }
      vmProfile.setCpuOvercommitRatio(Float.parseFloat(cluster_detail_cpu.getValue()));
      vmProfile.setMemoryOvercommitRatio(Float.parseFloat(cluster_detail_ram.getValue()));
      StartAnswer startAnswer=null;
      try {
        if (!changeState(vm,Event.OperationRetry,destHostId,work,Step.Prepare)) {
          throw new ConcurrentOperationException("Unable to update the state of the Virtual Machine");
        }
      }
 catch (      NoTransitionException e1) {
        throw new ConcurrentOperationException(e1.getMessage());
      }
      try {
        if (s_logger.isDebugEnabled()) {
          s_logger.debug("VM is being created in podId: " + vm.getPodIdToDeployIn());
        }
        _networkMgr.prepare(vmProfile,dest,ctx);
        if (vm.getHypervisorType() != HypervisorType.BareMetal) {
          volumeMgr.prepare(vmProfile,dest);
        }
        if (!reuseVolume) {
          reuseVolume=true;
        }
        Commands cmds=null;
        vmGuru.finalizeVirtualMachineProfile(vmProfile,dest,ctx);
        VirtualMachineTO vmTO=hvGuru.implement(vmProfile);
        handlePath(vmTO.getDisks(),vm.getHypervisorType());
        cmds=new Commands(Command.OnError.Stop);
        cmds.addCommand(new StartCommand(vmTO,dest.getHost(),getExecuteInSequence()));
        vmGuru.finalizeDeployment(cmds,vmProfile,dest,ctx);
        work=_workDao.findById(work.getId());
        if (work == null || work.getStep() != Step.Prepare) {
          throw new ConcurrentOperationException("Work steps have been changed: " + work);
        }
        _workDao.updateStep(work,Step.Starting);
        _agentMgr.send(destHostId,cmds);
        _workDao.updateStep(work,Step.Started);
        startAnswer=cmds.getAnswer(StartAnswer.class);
        if (startAnswer != null && startAnswer.getResult()) {
          handlePath(vmTO.getDisks(),startAnswer.getIqnToPath());
          String host_guid=startAnswer.getHost_guid();
          if (host_guid != null) {
            HostVO finalHost=_resourceMgr.findHostByGuid(host_guid);
            if (finalHost == null) {
              throw new CloudRuntimeException("Host Guid " + host_guid + " doesn't exist in DB, something wrong here");
            }
            destHostId=finalHost.getId();
          }
          if (vmGuru.finalizeStart(vmProfile,destHostId,cmds,ctx)) {
            syncDiskChainChange(startAnswer);
            if (!changeState(vm,Event.OperationSucceeded,destHostId,work,Step.Done)) {
              throw new ConcurrentOperationException("Unable to transition to a new state.");
            }
            startedVm=vm;
            if (s_logger.isDebugEnabled()) {
              s_logger.debug("Start completed for VM " + vm);
            }
            return;
          }
 else {
            if (s_logger.isDebugEnabled()) {
              s_logger.info("The guru did not like the answers so stopping " + vm);
            }
            StopCommand cmd=new StopCommand(vm,getExecuteInSequence());
            StopAnswer answer=(StopAnswer)_agentMgr.easySend(destHostId,cmd);
            if (answer != null) {
              String hypervisortoolsversion=answer.getHypervisorToolsVersion();
              if (hypervisortoolsversion != null) {
                if (vm.getType() == VirtualMachine.Type.User) {
                  UserVmVO userVm=_userVmDao.findById(vm.getId());
                  _userVmDao.loadDetails(userVm);
                  userVm.setDetail("hypervisortoolsversion",hypervisortoolsversion);
                  _userVmDao.saveDetails(userVm);
                }
              }
            }
            if (answer == null || !answer.getResult()) {
              s_logger.warn("Unable to stop " + vm + " due to "+ (answer != null ? answer.getDetails() : "no answers"));
              _haMgr.scheduleStop(vm,destHostId,WorkType.ForceStop);
              throw new ExecutionException("Unable to stop " + vm + " so we are unable to retry the start operation");
            }
            throw new ExecutionException("Unable to start " + vm + " due to error in finalizeStart, not retrying");
          }
        }
        s_logger.info("Unable to start VM on " + dest.getHost() + " due to "+ (startAnswer == null ? " no start answer" : startAnswer.getDetails()));
      }
 catch (      OperationTimedoutException e) {
        s_logger.debug("Unable to send the start command to host " + dest.getHost());
        if (e.isActive()) {
          _haMgr.scheduleStop(vm,destHostId,WorkType.CheckStop);
        }
        canRetry=false;
        throw new AgentUnavailableException("Unable to start " + vm.getHostName(),destHostId,e);
      }
catch (      ResourceUnavailableException e) {
        s_logger.info("Unable to contact resource.",e);
        if (!avoids.add(e)) {
          if (e.getScope() == Volume.class || e.getScope() == Nic.class) {
            throw e;
          }
 else {
            s_logger.warn("unexpected ResourceUnavailableException : " + e.getScope().getName(),e);
            throw e;
          }
        }
      }
catch (      InsufficientCapacityException e) {
        s_logger.info("Insufficient capacity ",e);
        if (!avoids.add(e)) {
          if (e.getScope() == Volume.class || e.getScope() == Nic.class) {
            throw e;
          }
 else {
            s_logger.warn("unexpected InsufficientCapacityException : " + e.getScope().getName(),e);
          }
        }
      }
catch (      Exception e) {
        s_logger.error("Failed to start instance " + vm,e);
        throw new AgentUnavailableException("Unable to start instance due to " + e.getMessage(),destHostId,e);
      }
 finally {
        if (startedVm == null && canRetry) {
          Step prevStep=work.getStep();
          _workDao.updateStep(work,Step.Release);
          if ((prevStep == Step.Started || prevStep == Step.Starting) && (startAnswer != null && startAnswer.getResult())) {
            cleanup(vmGuru,vmProfile,work,Event.OperationFailed,false);
          }
 else {
            cleanup(vmGuru,vmProfile,work,Event.OperationFailed,true);
          }
        }
      }
    }
  }
  finally {
    if (startedVm == null) {
      if (canRetry) {
        try {
          changeState(vm,Event.OperationFailed,null,work,Step.Done);
        }
 catch (        NoTransitionException e) {
          throw new ConcurrentOperationException(e.getMessage());
        }
      }
    }
    if (planToDeploy != null) {
      planToDeploy.setAvoids(avoids);
    }
  }
  if (startedVm == null) {
    throw new CloudRuntimeException("Unable to start instance '" + vm.getHostName() + "' ("+ vm.getUuid()+ "), see management server log for details");
  }
}
