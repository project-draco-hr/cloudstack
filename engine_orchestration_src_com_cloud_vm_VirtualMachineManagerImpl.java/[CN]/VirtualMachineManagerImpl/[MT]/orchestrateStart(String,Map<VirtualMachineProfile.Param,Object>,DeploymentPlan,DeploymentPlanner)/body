{
  final CallContext cctxt=CallContext.current();
  final Account account=cctxt.getCallingAccount();
  final User caller=cctxt.getCallingUser();
  VMInstanceVO vm=_vmDao.findByUuid(vmUuid);
  final VirtualMachineGuru vmGuru=getVmGuru(vm);
  final Ternary<VMInstanceVO,ReservationContext,ItWorkVO> start=changeToStartState(vmGuru,vm,caller,account);
  if (start == null) {
    return;
  }
  vm=start.first();
  final ReservationContext ctx=start.second();
  ItWorkVO work=start.third();
  VMInstanceVO startedVm=null;
  final ServiceOfferingVO offering=_offeringDao.findById(vm.getId(),vm.getServiceOfferingId());
  final VirtualMachineTemplate template=_entityMgr.findByIdIncludingRemoved(VirtualMachineTemplate.class,vm.getTemplateId());
  if (s_logger.isDebugEnabled()) {
    s_logger.debug("Trying to deploy VM, vm has dcId: " + vm.getDataCenterId() + " and podId: "+ vm.getPodIdToDeployIn());
  }
  DataCenterDeployment plan=new DataCenterDeployment(vm.getDataCenterId(),vm.getPodIdToDeployIn(),null,null,null,null,ctx);
  if (planToDeploy != null && planToDeploy.getDataCenterId() != 0) {
    if (s_logger.isDebugEnabled()) {
      s_logger.debug("advanceStart: DeploymentPlan is provided, using dcId:" + planToDeploy.getDataCenterId() + ", podId: "+ planToDeploy.getPodId()+ ", clusterId: "+ planToDeploy.getClusterId()+ ", hostId: "+ planToDeploy.getHostId()+ ", poolId: "+ planToDeploy.getPoolId());
    }
    plan=new DataCenterDeployment(planToDeploy.getDataCenterId(),planToDeploy.getPodId(),planToDeploy.getClusterId(),planToDeploy.getHostId(),planToDeploy.getPoolId(),planToDeploy.getPhysicalNetworkId(),ctx);
  }
  final HypervisorGuru hvGuru=_hvGuruMgr.getGuru(vm.getHypervisorType());
  boolean canRetry=true;
  ExcludeList avoids=null;
  try {
    final Journal journal=start.second().getJournal();
    if (planToDeploy != null) {
      avoids=planToDeploy.getAvoids();
    }
    if (avoids == null) {
      avoids=new ExcludeList();
    }
    if (s_logger.isDebugEnabled()) {
      s_logger.debug("Deploy avoids pods: " + avoids.getPodsToAvoid() + ", clusters: "+ avoids.getClustersToAvoid()+ ", hosts: "+ avoids.getHostsToAvoid());
    }
    boolean planChangedByVolume=false;
    boolean reuseVolume=true;
    final DataCenterDeployment originalPlan=plan;
    int retry=StartRetry.value();
    while (retry-- != 0) {
      if (reuseVolume) {
        final List<VolumeVO> vols=_volsDao.findReadyRootVolumesByInstance(vm.getId());
        for (        final VolumeVO vol : vols) {
          final Long volTemplateId=vol.getTemplateId();
          if (volTemplateId != null && volTemplateId.longValue() != template.getId()) {
            if (s_logger.isDebugEnabled()) {
              s_logger.debug(vol + " of " + vm+ " is READY, but template ids don't match, let the planner reassign a new pool");
            }
            continue;
          }
          final StoragePool pool=(StoragePool)dataStoreMgr.getPrimaryDataStore(vol.getPoolId());
          if (!pool.isInMaintenance()) {
            if (s_logger.isDebugEnabled()) {
              s_logger.debug("Root volume is ready, need to place VM in volume's cluster");
            }
            final long rootVolDcId=pool.getDataCenterId();
            final Long rootVolPodId=pool.getPodId();
            final Long rootVolClusterId=pool.getClusterId();
            if (planToDeploy != null && planToDeploy.getDataCenterId() != 0) {
              final Long clusterIdSpecified=planToDeploy.getClusterId();
              if (clusterIdSpecified != null && rootVolClusterId != null) {
                if (rootVolClusterId.longValue() != clusterIdSpecified.longValue()) {
                  if (s_logger.isDebugEnabled()) {
                    s_logger.debug("Cannot satisfy the deployment plan passed in since the ready Root volume is in different cluster. volume's cluster: " + rootVolClusterId + ", cluster specified: "+ clusterIdSpecified);
                  }
                  throw new ResourceUnavailableException("Root volume is ready in different cluster, Deployment plan provided cannot be satisfied, unable to create a deployment for " + vm,Cluster.class,clusterIdSpecified);
                }
              }
              plan=new DataCenterDeployment(planToDeploy.getDataCenterId(),planToDeploy.getPodId(),planToDeploy.getClusterId(),planToDeploy.getHostId(),vol.getPoolId(),null,ctx);
            }
 else {
              plan=new DataCenterDeployment(rootVolDcId,rootVolPodId,rootVolClusterId,null,vol.getPoolId(),null,ctx);
              if (s_logger.isDebugEnabled()) {
                s_logger.debug(vol + " is READY, changing deployment plan to use this pool's dcId: " + rootVolDcId+ " , podId: "+ rootVolPodId+ " , and clusterId: "+ rootVolClusterId);
              }
              planChangedByVolume=true;
            }
          }
        }
      }
      final Account owner=_entityMgr.findById(Account.class,vm.getAccountId());
      final VirtualMachineProfileImpl vmProfile=new VirtualMachineProfileImpl(vm,template,offering,owner,params);
      DeployDestination dest=null;
      try {
        dest=_dpMgr.planDeployment(vmProfile,plan,avoids,planner);
      }
 catch (      final AffinityConflictException e2) {
        s_logger.warn("Unable to create deployment, affinity rules associted to the VM conflict",e2);
        throw new CloudRuntimeException("Unable to create deployment, affinity rules associted to the VM conflict");
      }
      if (dest == null) {
        if (planChangedByVolume) {
          plan=originalPlan;
          planChangedByVolume=false;
          reuseVolume=false;
          continue;
        }
        throw new InsufficientServerCapacityException("Unable to create a deployment for " + vmProfile,DataCenter.class,plan.getDataCenterId(),areAffinityGroupsAssociated(vmProfile));
      }
      if (dest != null) {
        avoids.addHost(dest.getHost().getId());
        journal.record("Deployment found ",vmProfile,dest);
      }
      long destHostId=dest.getHost().getId();
      vm.setPodIdToDeployIn(dest.getPod().getId());
      final Long cluster_id=dest.getCluster().getId();
      final ClusterDetailsVO cluster_detail_cpu=_clusterDetailsDao.findDetail(cluster_id,"cpuOvercommitRatio");
      final ClusterDetailsVO cluster_detail_ram=_clusterDetailsDao.findDetail(cluster_id,"memoryOvercommitRatio");
      if (_uservmDetailsDao.findDetail(vm.getId(),"cpuOvercommitRatio") == null && (Float.parseFloat(cluster_detail_cpu.getValue()) > 1f || Float.parseFloat(cluster_detail_ram.getValue()) > 1f)) {
        _uservmDetailsDao.addDetail(vm.getId(),"cpuOvercommitRatio",cluster_detail_cpu.getValue(),true);
        _uservmDetailsDao.addDetail(vm.getId(),"memoryOvercommitRatio",cluster_detail_ram.getValue(),true);
      }
 else       if (_uservmDetailsDao.findDetail(vm.getId(),"cpuOvercommitRatio") != null) {
        _uservmDetailsDao.addDetail(vm.getId(),"cpuOvercommitRatio",cluster_detail_cpu.getValue(),true);
        _uservmDetailsDao.addDetail(vm.getId(),"memoryOvercommitRatio",cluster_detail_ram.getValue(),true);
      }
      vmProfile.setCpuOvercommitRatio(Float.parseFloat(cluster_detail_cpu.getValue()));
      vmProfile.setMemoryOvercommitRatio(Float.parseFloat(cluster_detail_ram.getValue()));
      StartAnswer startAnswer=null;
      try {
        if (!changeState(vm,Event.OperationRetry,destHostId,work,Step.Prepare)) {
          throw new ConcurrentOperationException("Unable to update the state of the Virtual Machine");
        }
      }
 catch (      final NoTransitionException e1) {
        throw new ConcurrentOperationException(e1.getMessage());
      }
      try {
        if (s_logger.isDebugEnabled()) {
          s_logger.debug("VM is being created in podId: " + vm.getPodIdToDeployIn());
        }
        _networkMgr.prepare(vmProfile,dest,ctx);
        if (vm.getHypervisorType() != HypervisorType.BareMetal) {
          volumeMgr.prepare(vmProfile,dest);
        }
        if (!reuseVolume) {
          reuseVolume=true;
        }
        Commands cmds=null;
        vmGuru.finalizeVirtualMachineProfile(vmProfile,dest,ctx);
        final VirtualMachineTO vmTO=hvGuru.implement(vmProfile);
        handlePath(vmTO.getDisks(),vm.getHypervisorType());
        cmds=new Commands(Command.OnError.Stop);
        cmds.addCommand(new StartCommand(vmTO,dest.getHost(),getExecuteInSequence(vm.getHypervisorType())));
        vmGuru.finalizeDeployment(cmds,vmProfile,dest,ctx);
        work=_workDao.findById(work.getId());
        if (work == null || work.getStep() != Step.Prepare) {
          throw new ConcurrentOperationException("Work steps have been changed: " + work);
        }
        _workDao.updateStep(work,Step.Starting);
        _agentMgr.send(destHostId,cmds);
        _workDao.updateStep(work,Step.Started);
        startAnswer=cmds.getAnswer(StartAnswer.class);
        if (startAnswer != null && startAnswer.getResult()) {
          handlePath(vmTO.getDisks(),startAnswer.getIqnToPath());
          final String host_guid=startAnswer.getHost_guid();
          if (host_guid != null) {
            final HostVO finalHost=_resourceMgr.findHostByGuid(host_guid);
            if (finalHost == null) {
              throw new CloudRuntimeException("Host Guid " + host_guid + " doesn't exist in DB, something wrong here");
            }
            destHostId=finalHost.getId();
          }
          if (vmGuru.finalizeStart(vmProfile,destHostId,cmds,ctx)) {
            syncDiskChainChange(startAnswer);
            if (!changeState(vm,Event.OperationSucceeded,destHostId,work,Step.Done)) {
              throw new ConcurrentOperationException("Unable to transition to a new state.");
            }
            final GPUDeviceTO gpuDevice=startAnswer.getVirtualMachine().getGpuDevice();
            if (gpuDevice != null) {
              _resourceMgr.updateGPUDetails(destHostId,gpuDevice.getGroupDetails());
            }
            startedVm=vm;
            if (s_logger.isDebugEnabled()) {
              s_logger.debug("Start completed for VM " + vm);
            }
            return;
          }
 else {
            if (s_logger.isDebugEnabled()) {
              s_logger.info("The guru did not like the answers so stopping " + vm);
            }
            final StopCommand cmd=new StopCommand(vm,getExecuteInSequence(vm.getHypervisorType()),false);
            final Answer answer=_agentMgr.easySend(destHostId,cmd);
            if (answer != null && answer instanceof StopAnswer) {
              final StopAnswer stopAns=(StopAnswer)answer;
              if (vm.getType() == VirtualMachine.Type.User) {
                final String platform=stopAns.getPlatform();
                if (platform != null) {
                  final Map<String,String> vmmetadata=new HashMap<String,String>();
                  vmmetadata.put(vm.getInstanceName(),platform);
                  syncVMMetaData(vmmetadata);
                }
              }
            }
            if (answer == null || !answer.getResult()) {
              s_logger.warn("Unable to stop " + vm + " due to "+ (answer != null ? answer.getDetails() : "no answers"));
              _haMgr.scheduleStop(vm,destHostId,WorkType.ForceStop);
              throw new ExecutionException("Unable to stop " + vm + " so we are unable to retry the start operation");
            }
            throw new ExecutionException("Unable to start " + vm + " due to error in finalizeStart, not retrying");
          }
        }
        s_logger.info("Unable to start VM on " + dest.getHost() + " due to "+ (startAnswer == null ? " no start answer" : startAnswer.getDetails()));
        if (startAnswer != null && startAnswer.getContextParam("stopRetry") != null) {
          break;
        }
      }
 catch (      final OperationTimedoutException e) {
        s_logger.debug("Unable to send the start command to host " + dest.getHost());
        if (e.isActive()) {
          _haMgr.scheduleStop(vm,destHostId,WorkType.CheckStop);
        }
        canRetry=false;
        throw new AgentUnavailableException("Unable to start " + vm.getHostName(),destHostId,e);
      }
catch (      final ResourceUnavailableException e) {
        s_logger.info("Unable to contact resource.",e);
        if (!avoids.add(e)) {
          if (e.getScope() == Volume.class || e.getScope() == Nic.class) {
            throw e;
          }
 else {
            s_logger.warn("unexpected ResourceUnavailableException : " + e.getScope().getName(),e);
            throw e;
          }
        }
      }
catch (      final InsufficientCapacityException e) {
        s_logger.info("Insufficient capacity ",e);
        if (!avoids.add(e)) {
          if (e.getScope() == Volume.class || e.getScope() == Nic.class) {
            throw e;
          }
 else {
            s_logger.warn("unexpected InsufficientCapacityException : " + e.getScope().getName(),e);
          }
        }
      }
catch (      final ExecutionException e) {
        s_logger.error("Failed to start instance " + vm,e);
        throw new AgentUnavailableException("Unable to start instance due to " + e.getMessage(),destHostId,e);
      }
catch (      final NoTransitionException e) {
        s_logger.error("Failed to start instance " + vm,e);
        throw new AgentUnavailableException("Unable to start instance due to " + e.getMessage(),destHostId,e);
      }
 finally {
        if (startedVm == null && canRetry) {
          final Step prevStep=work.getStep();
          _workDao.updateStep(work,Step.Release);
          if ((prevStep == Step.Started || prevStep == Step.Starting) && startAnswer != null && startAnswer.getResult()) {
            cleanup(vmGuru,vmProfile,work,Event.OperationFailed,false);
          }
 else {
            cleanup(vmGuru,vmProfile,work,Event.OperationFailed,true);
          }
        }
      }
    }
  }
  finally {
    if (startedVm == null) {
      if (canRetry) {
        try {
          changeState(vm,Event.OperationFailed,null,work,Step.Done);
        }
 catch (        final NoTransitionException e) {
          throw new ConcurrentOperationException(e.getMessage());
        }
      }
    }
    if (planToDeploy != null) {
      planToDeploy.setAvoids(avoids);
    }
  }
  if (startedVm == null) {
    throw new CloudRuntimeException("Unable to start instance '" + vm.getHostName() + "' ("+ vm.getUuid()+ "), see management server log for details");
  }
}
