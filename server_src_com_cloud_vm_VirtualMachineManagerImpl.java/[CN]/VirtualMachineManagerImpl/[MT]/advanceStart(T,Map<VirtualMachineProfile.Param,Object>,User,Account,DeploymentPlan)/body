{
  long vmId=vm.getId();
  VirtualMachineGuru<T> vmGuru;
  if (vm.getHypervisorType() == HypervisorType.BareMetal) {
    vmGuru=getBareMetalVmGuru(vm);
  }
 else {
    vmGuru=getVmGuru(vm);
  }
  vm=vmGuru.findById(vm.getId());
  Ternary<T,ReservationContext,ItWorkVO> start=changeToStartState(vmGuru,vm,caller,account);
  if (start == null) {
    return vmGuru.findById(vmId);
  }
  vm=start.first();
  ReservationContext ctx=start.second();
  ItWorkVO work=start.third();
  T startedVm=null;
  ServiceOfferingVO offering=_offeringDao.findById(vm.getServiceOfferingId());
  VMTemplateVO template=_templateDao.findById(vm.getTemplateId());
  DataCenterDeployment plan=new DataCenterDeployment(vm.getDataCenterIdToDeployIn(),vm.getPodIdToDeployIn(),null,null,null);
  if (planToDeploy != null) {
    if (s_logger.isDebugEnabled()) {
      s_logger.debug("advanceStart: DeploymentPlan is provided, using that plan to deploy");
    }
    plan=(DataCenterDeployment)planToDeploy;
  }
  HypervisorGuru hvGuru=_hvGuruMgr.getGuru(vm.getHypervisorType());
  boolean canRetry=true;
  try {
    Journal journal=start.second().getJournal();
    ExcludeList avoids=new ExcludeList();
    if (vm.getType().equals(VirtualMachine.Type.DomainRouter)) {
      List<DomainRouterVO> routers=_routerDao.findBy(vm.getAccountId(),vm.getDataCenterIdToDeployIn());
      for (      DomainRouterVO router : routers) {
        if (router.hostId != null) {
          avoids.addHost(router.hostId);
          s_logger.info("Router: try to avoid host " + router.hostId);
        }
      }
    }
    int retry=_retry;
    while (retry-- != 0) {
      List<VolumeVO> vols=_volsDao.findReadyRootVolumesByInstance(vm.getId());
      for (      VolumeVO vol : vols) {
        Long volTemplateId=vol.getTemplateId();
        if (volTemplateId != null && volTemplateId.longValue() != template.getId()) {
          if (s_logger.isDebugEnabled()) {
            s_logger.debug(vol + " of " + vm+ " is READY, but template ids don't match, let the planner reassign a new pool");
          }
          continue;
        }
        StoragePoolVO pool=_storagePoolDao.findById(vol.getPoolId());
        if (!pool.isInMaintenance()) {
          if (s_logger.isDebugEnabled()) {
            s_logger.debug("Root volume is ready, need to place VM in volume's cluster");
          }
          long rootVolDcId=pool.getDataCenterId();
          Long rootVolPodId=pool.getPodId();
          Long rootVolClusterId=pool.getClusterId();
          if (planToDeploy != null) {
            Long clusterIdSpecified=planToDeploy.getClusterId();
            if (clusterIdSpecified != null && rootVolClusterId != null) {
              if (rootVolClusterId.longValue() != clusterIdSpecified.longValue()) {
                if (s_logger.isDebugEnabled()) {
                  s_logger.debug("Cannot satisfy the deployment plan passed in since the ready Root volume is in different cluster. volume's cluster: " + rootVolClusterId + ", cluster specified: "+ clusterIdSpecified);
                }
                throw new ResourceUnavailableException("Root volume is ready in different cluster, Deployment plan provided cannot be satisfied, unable to create a deployment for " + vm,Cluster.class,clusterIdSpecified);
              }
            }
            plan=new DataCenterDeployment(planToDeploy.getDataCenterId(),planToDeploy.getPodId(),planToDeploy.getClusterId(),planToDeploy.getHostId(),vol.getPoolId());
          }
 else {
            plan=new DataCenterDeployment(rootVolDcId,rootVolPodId,rootVolClusterId,null,vol.getPoolId());
            if (s_logger.isDebugEnabled()) {
              s_logger.debug(vol + " is READY, changing deployment plan to use this pool's dcId: " + rootVolDcId+ " , podId: "+ rootVolPodId+ " , and clusterId: "+ rootVolClusterId);
            }
          }
        }
      }
      VirtualMachineProfileImpl<T> vmProfile=new VirtualMachineProfileImpl<T>(vm,template,offering,account,params);
      DeployDestination dest=null;
      for (      DeploymentPlanner planner : _planners) {
        if (planner.canHandle(vmProfile,plan,avoids)) {
          dest=planner.plan(vmProfile,plan,avoids);
        }
 else {
          continue;
        }
        if (dest != null) {
          avoids.addHost(dest.getHost().getId());
          journal.record("Deployment found ",vmProfile,dest);
          break;
        }
      }
      if (dest == null) {
        if (vm.getType().equals(VirtualMachine.Type.DomainRouter)) {
          avoids=new ExcludeList();
          s_logger.info("Router: cancel avoids ");
          for (          DeploymentPlanner planner : _planners) {
            if (planner.canHandle(vmProfile,plan,avoids)) {
              dest=planner.plan(vmProfile,plan,avoids);
            }
 else {
              continue;
            }
            if (dest != null) {
              avoids.addHost(dest.getHost().getId());
              journal.record("Deployment found ",vmProfile,dest);
              break;
            }
          }
        }
        if (dest == null) {
          throw new InsufficientServerCapacityException("Unable to create a deployment for " + vmProfile,DataCenter.class,plan.getDataCenterId());
        }
      }
      long destHostId=dest.getHost().getId();
      try {
        if (!changeState(vm,Event.OperationRetry,destHostId,work,Step.Prepare)) {
          throw new ConcurrentOperationException("Unable to update the state of the Virtual Machine");
        }
      }
 catch (      NoTransitionException e1) {
        throw new ConcurrentOperationException(e1.getMessage());
      }
      try {
        _networkMgr.prepare(vmProfile,dest,ctx);
        if (vm.getHypervisorType() != HypervisorType.BareMetal) {
          _storageMgr.prepare(vmProfile,dest);
        }
        vmGuru.finalizeVirtualMachineProfile(vmProfile,dest,ctx);
        VirtualMachineTO vmTO=hvGuru.implement(vmProfile);
        Commands cmds=new Commands(OnError.Stop);
        cmds.addCommand(new StartCommand(vmTO));
        vmGuru.finalizeDeployment(cmds,vmProfile,dest,ctx);
        vm.setPodId(dest.getPod().getId());
        work=_workDao.findById(work.getId());
        if (work == null || work.getStep() != Step.Prepare) {
          throw new ConcurrentOperationException("Work steps have been changed: " + work);
        }
        _workDao.updateStep(work,Step.Starting);
        _agentMgr.send(destHostId,cmds);
        _workDao.updateStep(work,Step.Started);
        Answer startAnswer=cmds.getAnswer(StartAnswer.class);
        if (startAnswer != null && startAnswer.getResult()) {
          if (vmGuru.finalizeStart(vmProfile,destHostId,cmds,ctx)) {
            if (!changeState(vm,Event.OperationSucceeded,destHostId,work,Step.Done)) {
              throw new ConcurrentOperationException("Unable to transition to a new state.");
            }
            startedVm=vm;
            if (s_logger.isDebugEnabled()) {
              s_logger.debug("Start completed for VM " + vm);
            }
            return startedVm;
          }
 else {
            if (s_logger.isDebugEnabled()) {
              s_logger.info("The guru did not like the answers so stopping " + vm);
            }
            StopCommand cmd=new StopCommand(vm.getInstanceName());
            StopAnswer answer=(StopAnswer)_agentMgr.easySend(destHostId,cmd);
            if (answer == null || !answer.getResult()) {
              s_logger.warn("Unable to stop " + vm + " due to "+ (answer != null ? answer.getDetails() : "no answers"));
              canRetry=false;
              _haMgr.scheduleStop(vm,destHostId,WorkType.ForceStop);
              throw new ExecutionException("Unable to stop " + vm + " so we are unable to retry the start operation");
            }
          }
        }
        s_logger.info("Unable to start VM on " + dest.getHost() + " due to "+ (startAnswer == null ? " no start answer" : startAnswer.getDetails()));
      }
 catch (      OperationTimedoutException e) {
        s_logger.debug("Unable to send the start command to host " + dest.getHost());
        if (e.isActive()) {
          _haMgr.scheduleStop(vm,destHostId,WorkType.CheckStop);
        }
        canRetry=false;
        throw new AgentUnavailableException("Unable to start " + vm.getHostName(),destHostId,e);
      }
catch (      ResourceUnavailableException e) {
        s_logger.info("Unable to contact resource.",e);
        if (!avoids.add(e)) {
          if (e.getScope() == Volume.class || e.getScope() == Nic.class) {
            throw e;
          }
 else {
            s_logger.warn("unexpected ResourceUnavailableException : " + e.getScope().getName(),e);
            throw e;
          }
        }
      }
catch (      InsufficientCapacityException e) {
        s_logger.info("Insufficient capacity ",e);
        if (!avoids.add(e)) {
          if (e.getScope() == Volume.class || e.getScope() == Nic.class) {
            throw e;
          }
 else {
            s_logger.warn("unexpected InsufficientCapacityException : " + e.getScope().getName(),e);
          }
        }
      }
catch (      Exception e) {
        s_logger.error("Failed to start instance " + vm,e);
        throw new AgentUnavailableException("Unable to start instance",destHostId,e);
      }
 finally {
        if (startedVm == null && canRetry) {
          _workDao.updateStep(work,Step.Release);
          cleanup(vmGuru,vmProfile,work,Event.OperationFailed,false,caller,account);
        }
      }
    }
  }
  finally {
    if (startedVm == null) {
      if (vm.getType().equals(VirtualMachine.Type.User) && (vm.getLastHostId() == null)) {
        _accountMgr.decrementResourceCount(vm.getAccountId(),ResourceType.user_vm);
      }
      if (canRetry) {
        try {
          changeState(vm,Event.OperationFailed,null,work,Step.Done);
        }
 catch (        NoTransitionException e) {
          throw new ConcurrentOperationException(e.getMessage());
        }
      }
    }
  }
  return startedVm;
}
