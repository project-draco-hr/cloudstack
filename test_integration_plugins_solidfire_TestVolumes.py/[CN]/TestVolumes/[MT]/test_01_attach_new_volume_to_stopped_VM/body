def test_01_attach_new_volume_to_stopped_VM(self):
    'Attach a volume to a stopped virtual machine, then start VM'
    self.virtual_machine.stop(self.apiClient)
    new_volume = Volume.create(self.apiClient, self.testdata[TestData.volume_2], account=self.account.name, domainid=self.domain.id, zoneid=self.zone.id, diskofferingid=self.disk_offering.id)
    self.cleanup.append(new_volume)
    self._check_and_get_cs_volume(new_volume.id, self.testdata[TestData.volume_2][TestData.diskName])
    new_volume = self.virtual_machine.attach_volume(self.apiClient, new_volume)
    newvolume = self._check_and_get_cs_volume(new_volume.id, self.testdata[TestData.volume_2][TestData.diskName])
    TestVolumes._start_vm(self.virtual_machine)
    vm = self._get_vm(self.virtual_machine.id)
    self.assertEqual(newvolume.virtualmachineid, vm.id, TestVolumes._volume_vm_id_and_vm_id_do_not_match_err_msg)
    self.assertEqual(vm.state.lower(), 'running', TestVolumes._vm_not_in_running_state_err_msg)
    sf_account_id = sf_util.get_sf_account_id(self.cs_api, self.account.id, self.primary_storage.id, self, TestVolumes._sf_account_id_should_be_non_zero_int_err_msg)
    sf_volume_size = sf_util.get_volume_size_with_hsr(self.cs_api, new_volume, self)
    self._verify_hsr(self.disk_offering.disksize, self.disk_offering.hypervisorsnapshotreserve, sf_volume_size)
    sf_vag_id = sf_util.get_vag_id(self.cs_api, self.cluster.id, self.primary_storage.id, self)
    sf_iscsi_name = sf_util.get_iqn(self.cs_api, new_volume, self)
    sf_volumes = self._get_active_sf_volumes(sf_account_id)
    sf_volume = sf_util.check_and_get_sf_volume(sf_volumes, newvolume.name, self)
    sf_util.check_size_and_iops(sf_volume, newvolume, sf_volume_size, self)
    sf_util.check_vag(sf_volume, sf_vag_id, self)
    self._check_host_side(sf_iscsi_name, vm.hostid)
    new_volume = self.virtual_machine.detach_volume(self.apiClient, new_volume)
